[
  {
    "path": "posts/2021-05-31-simulate-vasicek-rt/",
    "title": "simulate vasicek r(t)",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Joohan Cho",
        "url": {}
      }
    ],
    "date": "2021-05-31",
    "categories": [],
    "contents": "\n\n\nknitr::opts_chunk$set(echo = TRUE)\n\n\n\nSimulate Vasicek r(t)\n\n\n# Simulate Vasicek r(t)\nset.seed(3)\n\n# parameter 설정\nr0 <- 0.03\na <- 0.2\nb <- 0.03\nsigma <- 0.01\nn <- 10    # trials\nT <- 10    # (10년만기 국고채)\nh <- 3600    # subintervals\ndt <- T/h   \n\n\n# 시나리오 행렬 생성\nv_m <- as.data.frame(matrix(data=0, ncol = 21, nrow = h+1)) \nv_m[1,1:10] <- r0\ncolnames(v_m)=c(\"scenario1\",\"scenario2\",\"scenario3\",\"scenario4\",\"scenario5\",\n                \"scenario6\",\"scenario7\",\"scenario8\",\"scenario9\",\"scenario10\", \n                \"price1\", \"price2\", \"price3\", \"price4\", \"price5\",\n                \"price6\", \"price7\", \"price8\", \"price9\", \"price10\",\"t\")\n\nfor(j in 1:n){\n  for(i in 2:(h+1)){\n    dr <- a*(b-v_m[i-1,j])*dt + sigma*sqrt(dt)*rnorm(1,0,1)   # dr = a(b-r)dt + sigma*dz, where dz~N(0,dt) > using normal approximation\n    v_m[i,j] <- v_m[i-1,j] + dr   # r(t)\n  }\n} \n\nv_m[,21] <- seq(0, 3600)\nv_m[,21] <- v_m[,21]/3600\n\n\n# plot r(t)\nt <- seq(0, T, dt)\nmatplot(t, v_m[,1:10], type=\"l\", lty=3, col = 1:10, main=\"Short-Rate Paths\", ylab=\"r(t)\") \n\n\n\n# pricing bond\nBondprice <- function(rt, a, b, sigma, k){\n  rbar <- b-(0.5*sigma^2/a^2)  # k= T-t\n  b.t <- (1/a)*(1-exp(-k*a))   # B(t,T) \n  a.t <- exp(rbar*(b.t-k)-(b.t^2*sigma^2/(4*a)))   # A(t,T)\n  return(a.t*exp(-b.t*rt))\n}\n\nfor (i in 1:h+1){\n  for (j in 1:n){\n    v_m[i,j+10] <- Bondprice(v_m[i,j], a, b, sigma, v_m[i,21])  \n  }\n  \n}\n\nv_mp <- v_m[-1,]\n\nmatplot(seq(1/3600,T,dt), v_mp[,11:20], type=\"l\", lty=1, col = 1:10, main=\"Bond price\", ylab=\"P(t,T)\", xlab = \"maturity\")\n\n\n\n\nvasicek 모형을 이용한 이자율 simulation\n\n\n\n",
    "preview": "posts/2021-05-31-simulate-vasicek-rt/simulate-vasicek-rt_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2021-05-31T11:51:38+00:00",
    "input_file": "simulate-vasicek-rt.utf8.md"
  },
  {
    "path": "posts/2021-05-31-ameshousing/",
    "title": "Ameshousing",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Joohan Cho",
        "url": {}
      }
    ],
    "date": "2021-05-31",
    "categories": [],
    "contents": "\nAmeshousing\n\n [1] \"1st Flr SF\"      \"2nd Flr SF\"      \"3Ssn Porch\"     \n [4] \"Alley\"           \"Bedroom AbvGr\"   \"Bldg Type\"      \n [7] \"Bsmt Cond\"       \"Bsmt Exposure\"   \"Bsmt Full Bath\" \n[10] \"Bsmt Half Bath\"  \"Bsmt Qual\"       \"Bsmt Unf SF\"    \n[13] \"BsmtFin SF 1\"    \"BsmtFin SF 2\"    \"BsmtFin Type 1\" \n[16] \"BsmtFin Type 2\"  \"Central Air\"     \"Condition 1\"    \n[19] \"Condition 2\"     \"Electrical\"      \"Enclosed Porch\" \n[22] \"Exter Cond\"      \"Exter Qual\"      \"Exterior 1st\"   \n[25] \"Exterior 2nd\"    \"Fence\"           \"Fireplace Qu\"   \n[28] \"Fireplaces\"      \"Foundation\"      \"Full Bath\"      \n[31] \"Functional\"      \"Garage Area\"     \"Garage Cars\"    \n[34] \"Garage Cond\"     \"Garage Finish\"   \"Garage Qual\"    \n[37] \"Garage Type\"     \"Garage Yr Blt\"   \"Gr Liv Area\"    \n[40] \"Half Bath\"       \"Heating\"         \"Heating QC\"     \n[43] \"House Style\"     \"Kitchen AbvGr\"   \"Kitchen Qual\"   \n[46] \"Land Contour\"    \"Land Slope\"      \"Lot Area\"       \n[49] \"Lot Config\"      \"Lot Frontage\"    \"Lot Shape\"      \n[52] \"Low Qual Fin SF\" \"Mas Vnr Area\"    \"Mas Vnr Type\"   \n[55] \"Misc Feature\"    \"Misc Val\"        \"Mo Sold\"        \n[58] \"MS SubClass\"     \"MS Zoning\"       \"Neighborhood\"   \n[61] \"Open Porch SF\"   \"Order\"           \"Overall Cond\"   \n[64] \"Overall Qual\"    \"Paved Drive\"     \"PID\"            \n[67] \"Pool Area\"       \"Pool QC\"         \"Roof Matl\"      \n[70] \"Roof Style\"      \"Sale Condition\"  \"Sale Type\"      \n[73] \"SalePrice\"       \"Screen Porch\"    \"Street\"         \n[76] \"Total Bsmt SF\"   \"TotRms AbvGrd\"   \"Utilities\"      \n[79] \"Wood Deck SF\"    \"Year Built\"      \"Year Remod/Add\" \n[82] \"Yr Sold\"        \n\n필요한 library와 ames_raw의 변수를 확인한다.\n\n\n\ntarget 변수인 SalePrice를 이용한 histogram & boxplot. histogram을 보면 왼쪽으로 그래프가 치우쳐져 있는 것을 확인할 수 있다.\n\n\n\n데이터가 왼쪽을 치우쳐져 있기 때문에, 로그 변환 후 bins = 50 으로 설정하여 다시 histogram을 그린 결과 정규분포와 비슷한 모양을 가진다는 것을 알 수 있다. 하지만 tail이 상대적으로 짧은 느낌이고 중앙도 움푹 파인 부분이 있는 것을 확인할 수 있다.\n\n\n\n정규성을 확인하기 위해 raw data와 log data의 Q-Q plot을 그려보면, raw data는 꼬리로 갈수록 정규분포에서 많이 벗어나는 것을 알 수 있고, log data 또한 꼬리 부분은 벗어 나지만 상대적으로 raw data보다는 정규성을 가진다고 볼 수 있다.\n\n\n\nTarget 변수인 SalePrice에 대한 plot을 그려보면 대부분의 값이 100,000 ~ 300,000 사이인 것을 확인할 수 있다.\n\n\n\nSalePrice에 영향을 많이 줄 것 같은 변수인 Total Bsmt SF에 대한 histogram과 boxplot을 그려보았다. 그 결과 SalePrice와 무언가 비슷한 형태를 가진다는 것을 확인할 수 있다.\n\n# A tibble: 7 x 3\n  `MS Zoning`     n    ratio\n  <chr>       <int>    <dbl>\n1 A (agr)         2 0.000683\n2 I (all)         2 0.000683\n3 C (all)        25 0.00853 \n4 RH             27 0.00922 \n5 FV            139 0.0474  \n6 RM            462 0.158   \n7 RL           2273 0.776   \n\n\n이산형변수인 MS Zoning에 대해 table을 만들어보고 histogram을 그려보았다. RL이 가장 많고 I(all)과 A(agr)은 거의 없다고 봐도 무방할 것 같다. I(all)과 A(agr)와 같이 데이터가 많이 존재하지 않는 변수들은 분석에 큰 영향을 주지 않을 것으로 예상되어 이런 변수들을 묶어 ’other’이란 변수로 rename해주기로 한다.\n\n\n\n주요변수를 2개로 하고 나머지 변수들은 데이터가 많이 없기 때문에 ’other’로 만들어 주었다.\n\n\n\n또 다른 이산형 변수인 Neighborhood를 MS Zoning과 같은 방법으로 주요변수 26개를 이용해 그래프를 그렸다.\n\n\n\n다음은 순서가 있는 변수인 Kitchen Qual에 대해 histogram을 그리고 x축을 보기 쉽게 ‘Poor’, ‘Fair’, ‘Average/Typical’, ‘Good’, ‘Excellent’ 순서대로 나열하고 그래프를 그린다. ’poor’는 데이터가 없고 일반적인 수준인 ’Good’과 ’Average/Typical’이 가장 많은 것을 알 수 있다. 순서가 있는 경우에는 ’Poor’와 ’Excellent’가 데이터가 많이 없다고 하더라도 SalePrice에 미치는 영향이 많이 다를 수 있기 때문에 합쳐서 ’other’이라는 변수를 만드는 것은 분석에 방해가 될 것 같기도 하다.\n\n\n\n그 다음으로는 집이 팔린 날짜에 대한 자료이다. 그래프를 보면 알겠지만 5월, 6월, 7월에 특히 빈도가 높은 것을 알 수 있다. 그 외에는 거의 비슷한 수준이라고 봐도 무방할 것 같다.\n\n\n# A tibble: 15 x 2\n   `cut_width(\\`Year Built\\`, width = 10)`     n\n   <fct>                                   <int>\n 1 (1995,2005]                               627\n 2 (1955,1965]                               373\n 3 (1965,1975]                               339\n 4 (2005,2015]                               324\n 5 (1975,1985]                               252\n 6 (1945,1955]                               246\n 7 (1985,1995]                               208\n 8 (1915,1925]                               179\n 9 (1935,1945]                               133\n10 (1925,1935]                               101\n11 (1905,1915]                                86\n12 (1895,1905]                                38\n13 (1885,1895]                                13\n14 (1875,1885]                                 9\n15 [1865,1875]                                 2\n\n\n집이 지어진 년도에 대한 자료인데, 그래프를 보면 알겠지만 시간이 지날수록 전반적으로 상승하다가, 1980 ~ 1990년 사이에는 데이터가 많이 없는 것을 알 수 있다. 사회적인 영향이 있는지 확인해볼 필요가 있을 것 같다.\n\n\n\nSalePrice에 가장 영향을 많이 줄것이라고 생각했던 1) Total Bsmt SF 변수를 x축으로, SalePrice를 y축으로 2) log(Total Bsmt SF) 변수를 x축으로, SalePrice를 y축으로 해서 그래프 2개를 그려보았다.\nx가 0인 data와 x축 오른쪽끝에 보면 이상치와 같은 값이 2개가 존재하는 것을 확인할 수 있다.\n\n\n\nTotal Bsmt SF와 같이 Misc Val 변수도 2개의 그래프를 그려보았고, 그 결과 SalePrice에 영향을 많이 안준다는 것을 확인할 수 있었다.\n\n\n\nYear Built 변수는 일반적으로 생각하면 최신일수록 SalePrice가 높을 것이라고 예상할 수 있다. 그래프를 보아도 예상했던 것과 마찬가지인 것을 알 수 있다.\n\n\n\n본인은 처음 생각할 때, 수영장의 넓이가 넓을수록 집의 크기가 커질 것이고 그렇게 된다면 가격 또한 비쌀 것이라 생각했는데, 그래프를 그려보면 대부분의 집은 수영장이 없다는 것을 확인할 수 있었다. 따라서 이 변수 또한 SalePrice를 예측하는데 큰 도움이 되지 못할 것이라 생각한다.\n\n\n\nBedroom의 개수와 SalePrice에 대한 관계이다. 일반적으로 생각하기에 Bedroom이 많을 수록 가격이 비쌀 것이다 라고 생각할 수 있는데, 4개 까지는 그런 관계가 있지만 그 이후로는 오히려 가격이 내려간다는 것을 알 수 있다. 이 또한 직관적으로 생각한 것과는 많이 다른 부분이다.\n\n\n\nLot Shape, Land Contour와 SalePrice에 대한 각각의 자료인데 두 변수에 따라 SalePrice가 크게 달라지지는 않는 것으로 보인다. 이런 변수들은 분석할 때 독립변수로 두는 것이 큰 의미가 있을까 라는 의문을 만들어준다.\n처음 데이터를 보았을 때 변수가 82개로 너무 많다고 생각을 했었다. 기초통계분석을 하면서\n1. 모든 변수가 내가 원하는 target 변수를 분석할 때 생각보다 많이 쓰이지 않을 것이라고 생각했다. (ex. Lot Shape, Land Contour …)\n2. 그래프를 보면 처음 변수이름과 설명을 보고 생각했던 나의 직관과는 생각보다 많이 다르다는 것을 알 수 있다. (ex. Pool Area…) 또한 변수 안에서도 필요없거나 합쳐져야할 카테고리가 많은 것으로 보인다.\n3. 우리가 볼 수 있는 데이터 외에 추가적으로 사회적인 현상과 이슈 같은 것들이 target변수에 영향을 줄 수도 있을 것 같다. (ex. Year Built…)\n\n\n\n",
    "preview": "posts/2021-05-31-ameshousing/ameshousing_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2021-05-31T11:34:54+00:00",
    "input_file": "ameshousing.utf8.md"
  },
  {
    "path": "posts/2021-05-31-barrier-option-pricing/",
    "title": "Barrier option pricing",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Joohan Cho",
        "url": {}
      }
    ],
    "date": "2021-05-31",
    "categories": [],
    "contents": "\nPricing Barrier option\n\n\n# Assumptions\n\nscenario <- 100\ninterval <- 600\nt <- 1/(interval)\nr <- 0.03\nsigma <-0.4\nmu <- r-0.5*sigma^2\n\ns0 <- 100\nk <- 110\nbarrier <- 120\nset.seed(123)\n\n\n# Z\n\nz <- as.data.frame(matrix(rnorm(scenario*interval), nrow=scenario, ncol=interval))\n\nxx <- as.data.frame(matrix(data=0, nrow=scenario, ncol=interval+1))\n\nfor (i in 1:scenario){\n  for(j in 1:interval){\n    xx[i,j+1] <- xx[i,j] + (mu*t+(sigma*sqrt(t)*z[i,j]))\n  }\n}\n\n\nplot(x=seq(1, 600, 1),y=s0*exp(xx[3,2:601]), main = \"X(T)\", type = \"l\", ylab=\"X(t)\", xlab=\"interval\")\n\n\n\n## Payoff 식 만들어야함\n\nresult <- matrix(NA, scenario, 1)\n\nfor(i in 1:scenario){\n  result[i,1]<- exp(-r*1)*(s0*exp(xx[i,601])-k)  \n}\n\n\nmean(result[1:scenario,1])\n\n\n[1] -7.071878\n\n\n\n\n",
    "preview": "posts/2021-05-31-barrier-option-pricing/barrier-option-pricing_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2021-05-31T11:52:59+00:00",
    "input_file": "barrier-option-pricing.utf8.md"
  },
  {
    "path": "posts/2021-05-31-loss-models-simulation-part/",
    "title": "Loss models simulation part",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Joohan Cho",
        "url": {}
      }
    ],
    "date": "2021-05-31",
    "categories": [],
    "contents": "\n\n\n## Pareto Distribution\n\nset.seed(111)\nn <- 10000\nx <- as.data.frame(matrix(data=0, nrow=n, ncol=3))\n\nfor (i in 1:n){\n  x[i,1] <- 1000*((1-runif(1))^(-1/3)-1)\n}\n\nx[1,2] <- x[1,1]\n\nfor (i in 1:n){\n  x[i+1,2]<- x[i,2]+x[i+1,1]\n}\n\nfor (i in 1:n){\n  x[i,2] <- x[i,2]/i\n}\n\n\nx <- x[-10001,]\nplot(x=1:n, y=x[,2], type = \"l\", , main = \"Simulation Pareto Distribution\", xlab=\"# of simulations\", ylab=\"mean\")\nabline(h=500, col=\"red\")\n\n\n\nx[,3] <- cut(x$V1, breaks = c(-1,100,250,500,750,1000,1500,2500,5000,10000,1000000000000000,10000000000000000))\n\nk <- table(x$V3)\nk\n\n\n\n         (-1,100]         (100,250]         (250,500] \n             2511              2370              2122 \n        (500,750]       (750,1e+03]   (1e+03,1.5e+03] \n             1145               617               608 \n(1.5e+03,2.5e+03]   (2.5e+03,5e+03]     (5e+03,1e+04] \n              400               179                41 \n    (1e+04,1e+15]     (1e+15,1e+16] \n                7                 0 \n\nk_t <- t(k)\n\nc <- as.data.frame(matrix(data=k_t, nrow=11, ncol=1))\nc[1,2] <- 10000*(1-(1000/(100+1000))^3)\nc[2,2] <- 10000*((1-(1000/(250+1000))^3)-(1-(1000/(100+1000))^3))\nc[3,2] <- 10000*((1-(1000/(500+1000))^3)-(1-(1000/(250+1000))^3))\nc[4,2] <- 10000*((1-(1000/(750+1000))^3)-(1-(1000/(500+1000))^3))\nc[5,2] <- 10000*((1-(1000/(1000+1000))^3)-(1-(1000/(750+1000))^3))\nc[6,2] <- 10000*((1-(1000/(1500+1000))^3)-(1-(1000/(1000+1000))^3))\nc[7,2] <- 10000*((1-(1000/(2500+1000))^3)-(1-(1000/(1500+1000))^3))\nc[8,2] <- 10000*((1-(1000/(5000+1000))^3)-(1-(1000/(2500+1000))^3))\nc[9,2] <- 10000*((1-(1000/(10000+1000))^3)-(1-(1000/(5000+1000))^3))\nc[10,2] <- 10000-sum(c$V2[1:9]) \n\nc[,3] <- (c[,1]-c[,2])^2/c[,2]\n\nc[11,1] <- sum(c$V1[1:10])\nc[11,2] <- sum(c$V2[1:10])\nc[11,3] <- sum(c$V3[1:10])\nc\n\n\n      V1           V2          V3\n1   2511  2486.851991 0.234483733\n2   2370  2393.148009 0.223901873\n3   2122  2157.037037 0.569111213\n4   1145  1097.073750 2.093683698\n5    617   615.889213 0.002003361\n6    608   610.000000 0.006557377\n7    400   406.763848 0.112472250\n8    179   186.939855 0.337227726\n9     41    38.783148 0.126715642\n10     7     7.513148 0.035048009\n11 10000 10000.000000 3.741204881\n\ncolnames(x) =c(\"pseudorandom number\", \"mean\", \"interval\")\ncolnames(c) =c(\"observed\", \"expected\", \"chi-square\")\n\ncp <- function(x){\n  k=1-(1000/(x+1000))^3\n  return(k)\n}\n\nplot(cp, xlim = c(0,1000), main = \"cdf of pareto distribution\", ylab = \"F(x)\")\n\n\n\n## Discrete Mixtures\n\ndm <- as.data.frame(matrix(data = 0, nrow = 10000, ncol = 5))\ncolnames(dm) =c(\"u1\",\"u2\",\"interval\",\"x\", \"mean\")\n\n# 난수 생성 (u)\nfor (i in 1:10000){\n  for (j in 1:2){\n    dm[i,j] <- runif(1)  \n  }\n} \n\n# interval\ndm[,3] <- cut(dm$u1, breaks = c(0,0.3,0.8,1))\nm <- table(dm$interval)\nm\n\n\n\n  (0,0.3] (0.3,0.8]   (0.8,1] \n     3014      5003      1983 \n\n# generating psuedorandom sapmples\nfor (i in 1:10000){\n  if(dm[i,1]<=0.3){\n    dm[i,4] <- (-log(1-dm[i,2])/0.02) \n  }else if(0.3<dm[i,1] & dm[i,1]<=0.8){\n    dm[i,4] <- (-log(1-dm[i,2])/0.04)\n  }else{\n    dm[i,4] <- (-log(1-dm[i,2])/0.05)\n  }\n}\n\nmean(dm$x)\n\n\n[1] 31.7446\n\nsd(dm$x)\n\n\n[1] 36.37177\n\n# generating mean\ndm[1,5] <- dm[1,4]\nfor (i in 1:10000){\n  dm[i+1,5] <- dm[i,5]+dm[i+1,4]\n}\ndm <- dm[-10001,]\n\nfor (i in 1:10000){\n  dm[i,5] <- dm[i,5]/i\n}\n\n\n\n# graph mean\nplot(dm$mean, type = \"l\", main = \"Simulating Discrete Mixtures\", ylab = \"mean\", xlab = \"# of simulations\")\n\n\n\n## Time or Age of Death from a Life Table\nlt <- as.data.frame(matrix(data = 0, nrow = 10000, ncol = 4))\ncolnames(lt)=c(\"u\",\"interval\",\"x\", \"mean\")\n\n\n\n\n# 난수 생성 (u)\nfor (i in 1:10000){\n      lt[i,1] <- runif(1)  \n}\n\n# interval\nlt[,2] <- cut(lt$u, breaks = c(0,0.0810582,0.28575174,0.54316897,0.75811670,\n                               0.89218763,0.95881682,0.98629855,0.99597466,\n                               0.998494347,0.99974981,0.99994610))\n\n# generating psuedorandom sapmples\nfor (i in 1:10000){\n  if(lt[i,1]<=0.0810582){\n    lt[i,3] <- 0\n  }else if(0.0810582<lt[i,1] & lt[i,1]<=0.28575174){\n    lt[i,3] <- 1\n  }else if(0.28575174<lt[i,1] & lt[i,1]<=0.54316897){\n    lt[i,3] <- 2\n  }else if(0.54316897<lt[i,1] & lt[i,1]<=0.75811670){\n    lt[i,3] <- 3\n  }else if(0.75811670<lt[i,1] & lt[i,1]<=0.89218763){\n    lt[i,3] <- 4\n  }else if(0.89218763<lt[i,1] & lt[i,1]<=0.95881682){\n    lt[i,3] <- 5\n  }else if(0.95881682<lt[i,1] & lt[i,1]<=0.98629855){\n    lt[i,3] <- 6\n  }else if(0.98629855<lt[i,1] & lt[i,1]<=0.99597466){\n    lt[i,3] <- 7\n  }else if(0.99597466<lt[i,1] & lt[i,1]<=0.998494347){\n    lt[i,3] <- 8\n  }else if(0.998494347<lt[i,1] & lt[i,1]<=0.99974981){\n    lt[i,3] <- 9\n  }else if(0.99974981<lt[i,1] & lt[i,1]<=0.99994610){\n    lt[i,3] <- 10\n  }else{\n    lt[i,3] <- 11\n  }\n}\n\nmean(lt$x)\n\n\n[1] 2.4906\n\n# generating mean\nlt[1,4] <- lt[1,3]\nfor (i in 1:10000){\n  lt[i+1,4] <- lt[i,4]+lt[i+1,3]\n}\nlt <- lt[-10001,]\n\nfor (i in 1:10000){\n  lt[i,4] <- lt[i,4]/i\n}\n\n\n# graph mean\nplot(lt$mean, type = \"l\", main = \"Simulating Binomial distribution\", ylab = \"mean\", xlab = \"# of simulations\")\nabline(h=2.5, col=\"red\")\n\n\n\n# graph cdf of binomial\ny<-pbinom(0:11, size = 250, prob = 0.01)\nplot(0:11, y, type = \"h\", main = \"cdf of binomial distribution\", xlab = \"x\", ylab = \"u\")\n\n\n\ny\n\n\n [1] 0.08105852 0.28575174 0.54316897 0.75811670 0.89218763 0.95881682\n [7] 0.98629855 0.99597466 0.99894347 0.99974981 0.99994610 0.99998936\n\n## Simulating from the (a, b, 0) Class\n\n# Poisson\n# s생성\nset.seed(999)\nab_sp <- as.data.frame(matrix(data = 0, nrow = 10000, ncol = 21))\ncolnames(ab_sp)=c(\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\n               \"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\")\n\nfor (i in 1:10000){\n  for (j in 1:21){\n    ab_sp[i,j] <- -log(1-runif(1))/2.5\n  }\n}\n\n# t 생성\nab_tp <-as.data.frame(matrix(data = 0, nrow = 10000,ncol=21))\ncolnames(ab_tp)=c(\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\n                 \"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"mean\")\n\nab_tp[,1] <- ab_sp[,1]\n\nfor (j in 1:10000){\n  for (i in 1:20){\n    ab_tp[j,i+1] <- ab_tp[j,i]+ab_sp[j,i+1]\n  }\n}\n\nfor (j in 1:10000){\n  for (i in 1:20){\n    if(ab_tp[j,i] >=1){\n      ab_tp[j,i] <- NA\n    }else{\n      ab_tp[j,i] \n    }\n  }\n}\n\n\n# Binomial\n# s생성\nab_sb <- as.data.frame(matrix(data = 0, nrow = 10000, ncol = 21))\ncolnames(ab_sb)=c(\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\n                 \"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\")\n\nfor (i in 1:10000){\n  for (j in 1:21){\n    ab_sb[i,j] <- -log(1-runif(1))/(-250*log(1-0.01)+log(1-0.01)*j)\n  }\n}\n\n# t 생성\nab_tb <-as.data.frame(matrix(data = 0, nrow = 10000,ncol=21))\ncolnames(ab_tb)=c(\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\n                  \"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"mean\")\n\nab_tb[,1] <- ab_sb[,1]\n\nfor (j in 1:10000){\n  for (i in 1:20){\n    ab_tb[j,i+1] <- ab_tb[j,i]+ab_sb[j,i+1]\n  }\n}\n\nfor (j in 1:10000){\n  for (i in 1:20){\n    if(ab_tb[j,i] >=1){\n      ab_tb[j,i] <- NA\n    }else{\n      ab_tb[j,i] \n    }\n  }\n}\n\n\n\n# Negative Binomial\n# s생성\nab_sn <- as.data.frame(matrix(data = 0, nrow = 10000, ncol = 21))\ncolnames(ab_sn)=c(\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\n                  \"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\")\n\nfor (i in 1:10000){\n  for (j in 1:21){\n    ab_sn[i,j] <- -log(1-runif(1))/(250*log(1+0.01)+log(1+0.01)*j)\n  }\n}\n\n# t 생성\nab_tn <-as.data.frame(matrix(data = 0, nrow = 10000,ncol=21))\ncolnames(ab_tn)=c(\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\n                  \"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"mean\")\n\nab_tn[,1] <- ab_sn[,1]\n\nfor (j in 1:10000){\n  for (i in 1:20){\n    ab_tn[j,i+1] <- ab_tn[j,i]+ab_sn[j,i+1]\n  }\n}\n\nfor (j in 1:10000){\n  for (i in 1:20){\n    if(ab_tn[j,i] >=1){\n      ab_tn[j,i] <- NA\n    }else{\n      ab_tn[j,i] \n    }\n  }\n}\n\n\n\n# use inversion method to get normal distribution\n\nnd <- as.data.frame(matrix(data=0, nrow = 10000, ncol = 2))\ncolnames(nd)=c(\"u\",\"z\")\n\nfor (i in 1:10000){\n  nd[i,1] <- runif(1)\n}\n\nfor (i in 1:10000){\n  nd[i,2] <- qnorm(nd[i,1], 0, 1)\n}\n\n\n# Box-Muller\nrnorm.boxmuller = function(n, mean=0, sd=1){\n  u1 = runif(ceiling(n/2))\n  u2 = runif(ceiling(n/2))\n  z1 = sqrt(-2*log(u1))*cos(2*pi*u2)\n  z2 = sqrt(-2*log(u1))*sin(2*pi*u2)\n  c(z1, z2)[1:n]*sd+mean\n}\n\n\n\n# Polar method\nPolarMethod<-function(N)\n{\n  \n  x<-numeric(N)\n  y<-numeric(N)\n  z<-numeric(N)\n  \n  i<-1\n  \n  while(i<=N)\n  {u1<-runif(1)\n  u2<-runif(1)\n  v1<-(2*u1)-1\n  v2<-(2*u2)-1\n  s<-(v1^2)+(v2^2)\n  \n  if(s<=1)\n  {\n    x[i]<-((-2*log(s)/s)^(1/2))*v1\n    y[i]<-((-2*log(s)/s)^(1/2))*v2\n    z[i]<-(x[i]+y[i])/sqrt(2) #standarization\n    i<-i+1\n  }\n  else\n    i<-i-1\n  }\n  \n  return(z)\n}\nz<-PolarMethod(100000)\n\n# inversion method & Box-Muller & Polar method\n\npar(mfrow=c(1,2))\n\nhist(nd$z, freq = F, ylab = \"density\", main = \"Inversion method\", xlab = \"z\")\ncurve(dnorm(x),from=-3,to=3,add=TRUE, col=\"red\")\n\nhist(rnorm.boxmuller(100000), freq=F, ylab = \"density\", main = \"Box-Muller\", xlab = \"z\")\ncurve(dnorm(x),from=-3,to=3,add=TRUE, col=\"red\")\n\n\n\nhist(z, freq=F, ylab=\"density\", xlab=\" z\", main = \"Polar method\")\ncurve(dnorm(x),from=-3,to=3,add=TRUE, col=\"red\")\n\n\n# Determine n\npareto <- as.data.frame(matrix(data=0, nrow=10000, ncol=3))\ncolnames(pareto) <- c(\"x\", \"count F(1000)\", \"percentile\")\n\nfor (i in 1:10000){\n  pareto[i,1] <- 1000*((1-runif(1))^(-1/3)-1)\n}\n\nfor (i in 1:10000){\n  if(pareto[i,1]<=1000){\n    pareto[i,2] <- 1\n  }else{\n    pareto[i,2] <- 0\n  }\n}\n\n\npareto[,3] <- sort(pareto[,1])\n\n\nquantile(pareto[,3], c(0.9))\n\n\n    90% \n1187.95 \n\npareto[10001,1] <- mean(pareto[1:10000,1])\npareto[10001,2] <- sum(pareto[1:10000,2])/10000\n\n\n\n\n\n\n\n",
    "preview": "posts/2021-05-31-loss-models-simulation-part/loss-models-simulation-part_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2021-05-31T12:07:56+00:00",
    "input_file": "loss-models-simulation-part.utf8.md"
  },
  {
    "path": "posts/2021-05-31-hw-1/",
    "title": "Ridge & Lasso regression",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Joohan Cho",
        "url": {}
      }
    ],
    "date": "2021-05-31",
    "categories": [],
    "contents": "\n< R code>\n\n\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(magrittr)\nlibrary(skimr)\nlibrary(knitr)\nlibrary(janitor)\ntheme_set(theme_bw())\n\n\n\nData load\n\n\nfile_path <- \"/cloud/project\"\nfiles <- list.files(file_path)\nfiles\n\n\n [1] \"_posts\"        \"_site.yml\"     \"about.Rmd\"     \"docs\"         \n [5] \"index.Rmd\"     \"port.Rmd\"      \"project.Rproj\" \"README.md\"    \n [9] \"Selfie.jpg\"    \"test.csv\"      \"tobi.jpg\"      \"train.csv\"    \n\ntest <- read_csv(file.path(file_path, \"test.csv\"))%>% \n  janitor::clean_names()\ntrain <- read_csv(file.path(file_path, \"train.csv\"))%>% \n  janitor::clean_names() \n\n\n\nPreprecessing with recipe (전처리 레시피 만들기)\n\n\ninstall.packages(\"janitor\")\nlibrary(janitor)\nall_data <- bind_rows(train, test) %>% \n  janitor::clean_names()\n\n\n\nMake recipe\n\n\nhousing_recipe <- all_data %>% \n  recipe(sale_price ~ .) %>%\n  step_rm(id) %>% \n  step_log(sale_price) %>% \n  step_modeimpute(all_nominal()) %>% \n  step_dummy(all_nominal()) %>% \n  step_meanimpute(all_predictors()) %>%\n  step_normalize(all_predictors()) %>%\n  prep(training = all_data)\n\n\n\njuice the all_data2 and split\n\n\nall_data2 <- juice(housing_recipe)\n\n\n\n\n\ntrain_index <- seq_len(nrow(train))\ntrain2 <- all_data2[train_index,]\ntest2 <- all_data2[-train_index,]\n\n\n\nSplit the train into validation and train\n\n\nset.seed(2021)\nvalidation_split <- vfold_cv(train2, v = 10, strata = sale_price)\n\n\n\nRidge\nSet the tuning spec\n\n\ntune_spec <- linear_reg(penalty = tune(), # lambda\n                        mixture = 0) %>% # mixture= alpha, alpha=0:ridge, alpha=1:lasso\n    set_engine(\"glmnet\")\n\nparam_grid <- grid_regular(penalty(), levels = 100) \n\n\n\nSet workflow()\n\n\nworkflow <- workflow() %>%\n    add_model(tune_spec) %>%\n    add_formula(sale_price ~ .)\n\n\n\nTuning lambda and alpha\n\n\nlibrary(glmnet)\ntune_result <- workflow %>%\n    tune_grid(validation_split,\n              grid = param_grid,\n              metrics = metric_set(rmse))\n\ntune_result %>%\n  collect_metrics()\n\n\n# A tibble: 100 x 7\n    penalty .metric .estimator  mean     n std_err .config            \n      <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>              \n 1 1   e-10 rmse    standard   0.164    10  0.0203 Preprocessor1_Mode…\n 2 1.26e-10 rmse    standard   0.164    10  0.0203 Preprocessor1_Mode…\n 3 1.59e-10 rmse    standard   0.164    10  0.0203 Preprocessor1_Mode…\n 4 2.01e-10 rmse    standard   0.164    10  0.0203 Preprocessor1_Mode…\n 5 2.54e-10 rmse    standard   0.164    10  0.0203 Preprocessor1_Mode…\n 6 3.20e-10 rmse    standard   0.164    10  0.0203 Preprocessor1_Mode…\n 7 4.04e-10 rmse    standard   0.164    10  0.0203 Preprocessor1_Mode…\n 8 5.09e-10 rmse    standard   0.164    10  0.0203 Preprocessor1_Mode…\n 9 6.43e-10 rmse    standard   0.164    10  0.0203 Preprocessor1_Mode…\n10 8.11e-10 rmse    standard   0.164    10  0.0203 Preprocessor1_Mode…\n# … with 90 more rows\n\ntune_result\n\n\n# Tuning results\n# 10-fold cross-validation using stratification \n# A tibble: 10 x 4\n   splits             id     .metrics           .notes          \n   <list>             <chr>  <list>             <list>          \n 1 <split [1312/148]> Fold01 <tibble [100 × 5]> <tibble [0 × 1]>\n 2 <split [1312/148]> Fold02 <tibble [100 × 5]> <tibble [0 × 1]>\n 3 <split [1313/147]> Fold03 <tibble [100 × 5]> <tibble [0 × 1]>\n 4 <split [1313/147]> Fold04 <tibble [100 × 5]> <tibble [0 × 1]>\n 5 <split [1313/147]> Fold05 <tibble [100 × 5]> <tibble [0 × 1]>\n 6 <split [1314/146]> Fold06 <tibble [100 × 5]> <tibble [0 × 1]>\n 7 <split [1315/145]> Fold07 <tibble [100 × 5]> <tibble [0 × 1]>\n 8 <split [1316/144]> Fold08 <tibble [100 × 5]> <tibble [0 × 1]>\n 9 <split [1316/144]> Fold09 <tibble [100 × 5]> <tibble [0 × 1]>\n10 <split [1316/144]> Fold10 <tibble [100 × 5]> <tibble [0 × 1]>\n\nVisualization of the tunning result\n\n\ntune_best <- tune_result %>%\n    select_best(metric = \"rmse\")\n\ntune_best$penalty\n\n\n[1] 0.2477076\n\ntune_result %>%\n    collect_metrics() %>%\n    ggplot(aes(penalty, mean, color = .metric)) + \n    geom_line(size = 1.5) + \n    scale_x_log10() + \n    theme(legend.position = \"none\") + \n    labs(title = \"RMSE\")\n\n\n\n\n\n\ntune_result %>%\n  show_best()\n\n\n# A tibble: 5 x 7\n  penalty .metric .estimator  mean     n std_err .config              \n    <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1   0.248 rmse    standard   0.154    10 0.0118  Preprocessor1_Model0…\n2   0.313 rmse    standard   0.154    10 0.0107  Preprocessor1_Model0…\n3   0.196 rmse    standard   0.154    10 0.0130  Preprocessor1_Model0…\n4   0.394 rmse    standard   0.155    10 0.00959 Preprocessor1_Model0…\n5   0.156 rmse    standard   0.155    10 0.0141  Preprocessor1_Model0…\n\n\n\nelastic_model <- \n    linear_reg(penalty = tune_best$penalty,\n               mixture = 0) %>%\n    set_engine(\"glmnet\")\n\nelastic_fit <- \n    elastic_model %>%\n    fit(sale_price ~ ., data = train2)\n\noptions(max.print = 10)\n\nelastic_fit %>%\n    tidy() %>%\n    filter(estimate > 0.001)\n\n\n# A tibble: 110 x 3\n   term           estimate penalty\n   <chr>             <dbl>   <dbl>\n 1 (Intercept)    12.0       0.248\n 2 lot_frontage    0.00519   0.248\n 3 lot_area        0.00985   0.248\n 4 overall_qual    0.0426    0.248\n 5 overall_cond    0.0214    0.248\n 6 year_built      0.0125    0.248\n 7 year_remod_add  0.0172    0.248\n 8 mas_vnr_area    0.00896   0.248\n 9 bsmt_fin_sf1    0.0125    0.248\n10 bsmt_fin_sf2    0.00422   0.248\n# … with 100 more rows\n\ncoefficient vs lambda of ridge regression\n\n\ny <- data.matrix(train2[ , c(\"sale_price\")])\nx <- train2[, c(\"lot_frontage\", \"lot_area\", \"overall_qual\", \"overall_cond\", \"year_built\", \"year_remod_add\", \"mas_vnr_area\", \"bsmt_fin_sf1\", \"bsmt_fin_sf2\")] \nlambdas <- seq(0, 2, by = 0.1)\nfit_ridge <- glmnet(x, y, alpha = 0, lambda = lambdas)\nplot(fit_ridge, xlab = \"Lambda\", ylab = \"value\")\n\n\n\n\nLasso\nSet the tuning spec\n\n\ntune_spec1 <- linear_reg(penalty = tune(), # lambda\n                        mixture = 1) %>% # = alpha, alpha=0:ridge, alpha=1:lasso\n    set_engine(\"glmnet\")\nparam_grid1 <- grid_regular(penalty(), levels = 100) \n                        #  mixture(), \n                        #  levels = list(penalty = 100,\n                        #             mixture = 5))\n\n\n\nSet workflow()\n\n\nworkflow1 <- workflow() %>%\n    add_model(tune_spec1) %>%\n    add_formula(sale_price ~ .)\n\n\n\nTuning lambda and alpha\n\n\ntune_result1 <- workflow1 %>%\n    tune_grid(validation_split,\n              grid = param_grid1,\n              metrics = metric_set(rmse))\n\ntune_result1 %>%\n    collect_metrics()\n\n\n# A tibble: 100 x 7\n    penalty .metric .estimator  mean     n std_err .config            \n      <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>              \n 1 1   e-10 rmse    standard   0.199    10  0.0303 Preprocessor1_Mode…\n 2 1.26e-10 rmse    standard   0.199    10  0.0303 Preprocessor1_Mode…\n 3 1.59e-10 rmse    standard   0.199    10  0.0303 Preprocessor1_Mode…\n 4 2.01e-10 rmse    standard   0.199    10  0.0303 Preprocessor1_Mode…\n 5 2.54e-10 rmse    standard   0.199    10  0.0303 Preprocessor1_Mode…\n 6 3.20e-10 rmse    standard   0.199    10  0.0303 Preprocessor1_Mode…\n 7 4.04e-10 rmse    standard   0.199    10  0.0303 Preprocessor1_Mode…\n 8 5.09e-10 rmse    standard   0.199    10  0.0303 Preprocessor1_Mode…\n 9 6.43e-10 rmse    standard   0.199    10  0.0303 Preprocessor1_Mode…\n10 8.11e-10 rmse    standard   0.199    10  0.0303 Preprocessor1_Mode…\n# … with 90 more rows\n\nVisualization of the tunning result\n\n\ntune_best1 <- tune_result1 %>%\n    select_best(metric = \"rmse\")\n\ntune_best1$penalty\n\n\n[1] 0.007564633\n\n\n\ntune_result1 %>%\n    collect_metrics() %>%\n    ggplot(aes(penalty, mean, color = .metric)) + \n    geom_line(size = 1.5) + \n    scale_x_log10() + \n    theme(legend.position = \"none\") + \n    labs(title = \"RMSE\")\n\n\n\n\n\n\ntune_result1 %>%\n    show_best()\n\n\n# A tibble: 5 x 7\n  penalty .metric .estimator  mean     n std_err .config              \n    <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1 0.00756 rmse    standard   0.164    10  0.0215 Preprocessor1_Model0…\n2 0.00599 rmse    standard   0.165    10  0.0226 Preprocessor1_Model0…\n3 0.00955 rmse    standard   0.165    10  0.0202 Preprocessor1_Model0…\n4 0.00475 rmse    standard   0.165    10  0.0234 Preprocessor1_Model0…\n5 0.0120  rmse    standard   0.165    10  0.0186 Preprocessor1_Model0…\n\n\n\nelastic_model1 <- \n    linear_reg(penalty = tune_best1$penalty,\n               mixture = 1) %>%\n    set_engine(\"glmnet\")\nelastic_fit1 <- \n    elastic_model1 %>%\n    fit(sale_price ~ ., data = train2)\noptions(max.print = 10)\nelastic_fit1 %>%\n    tidy() %>%\n    filter(estimate > 0.001)\n\n\n# A tibble: 35 x 3\n   term           estimate penalty\n   <chr>             <dbl>   <dbl>\n 1 (Intercept)    12.0     0.00756\n 2 lot_area        0.00982 0.00756\n 3 overall_qual    0.107   0.00756\n 4 overall_cond    0.0343  0.00756\n 5 year_built      0.0418  0.00756\n 6 year_remod_add  0.0191  0.00756\n 7 total_bsmt_sf   0.0205  0.00756\n 8 x1st_flr_sf     0.00391 0.00756\n 9 gr_liv_area     0.108   0.00756\n10 bsmt_full_bath  0.0193  0.00756\n# … with 25 more rows\n\ncoefficient vs lambda of lasso regression\n\n\ny <- data.matrix(train2[ , c(\"sale_price\")])\nx1 <- train2[, c(\"lot_area\", \"overall_qual\", \"overall_cond\", \"year_built\", \"year_remod_add\", \"total_bsmt_sf\", \"x1st_flr_sf\", \"gr_liv_area\", \"bsmt_full_bath\")] \nlambdas <- seq(0, 2, by = 0.1)\nfit_lasso <- glmnet(x1, y, alpha = 1, lambda = lambdas)\nplot(fit_lasso, xlab = \"Lambda\", ylab = \"value\", main = \"Lasso\")\n\n\n\n\nplot ridge & lasso regression\n\n\npar(mfrow=c(1,2))\nplot(fit_ridge, xlab = \"Lambda\", ylab = \"value\", main = \"Ridge\")\nplot(fit_lasso, xlab = \"Lambda\", ylab = \"value\", main = \"Lasso\")\n\n\n\n\n\n\n\n",
    "preview": "posts/2021-05-31-hw-1/hw-1_files/figure-html5/unnamed-chunk-11-1.png",
    "last_modified": "2021-05-31T12:31:57+00:00",
    "input_file": "hw-1.utf8.md"
  }
]
